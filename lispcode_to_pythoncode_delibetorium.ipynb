{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# if needed, install and/or upgrade to the latest version of the OpenAI Python library\n",
        "%pip install --upgrade openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsObEaQoTT3B",
        "outputId": "7b4150e3-cd27-4005-e228-8ad84edb5328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/227.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/227.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "Du5CGAEw6R6d",
        "outputId": "a642d4ab-6ea0-4396-9a72-59cc8535ea4b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'openai'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-eb2e0fd1a63a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import the OpenAI Python library for calling the OpenAI API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mMODEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gpt-4-0125-preview\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# import the OpenAI Python library for calling the OpenAI API\n",
        "from openai import OpenAI\n",
        "import os\n",
        "MODEL = \"gpt-4-0125-preview\"\n",
        "\n",
        "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", \"###################################################\"))\n",
        "\n",
        "def analyze_and_categorize_responses(input_text, theme):\n",
        "    \"\"\"\n",
        "    Analyzes text and categorizes responses into solutions, metrics, and barriers.\n",
        "    \"\"\"\n",
        "    prompt_analysis = (\n",
        "        f\"I want you to give me a bullet list of all the significantly different answers mentioned in a piece of text. \\n\"\n",
        "        \"Do NOT mention an answer more than once - be sure to remove duplicate points.\\n\"\n",
        "        \"I am interested in the following types of answers:\\n\"\n",
        "        f\"- SOLUTION: a way to achieve success in {theme}.\\n\"\n",
        "        f\"- METRIC: a way to measure the success of {theme}.\\n\"\n",
        "        f\"- BARRIER: a barrier to the success of {theme}.\\n\\n\"\n",
        "        \"For each point, give me the type of point (METRIC, BARRIER, or SOLUTION) followed by, IN THE SAME LINE, all the text describing that point.\\n\"\n",
        "        \"Include enough context so each point makes sense on its own.\\n\"\n",
        "        \"If there are no points in the text, answer NONE.\\n\\n\"\n",
        "        f\"Text: \\\"{input_text}\\\"\"\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    analysis_result = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\":  prompt_analysis},\n",
        "    ],\n",
        "        temperature=0.5,\n",
        "        max_tokens=1500,\n",
        "        top_p=1.0,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    ).choices[0].message.content\n",
        "\n",
        "    return analysis_result\n",
        "\n",
        "def find_cluster_for_response(question, point, clusters):\n",
        "    \"\"\"\n",
        "    Determines the best cluster for each categorized response.\n",
        "    \"\"\"\n",
        "    prompt_cluster = (\n",
        "        f\"Give me the ID of the best category to put the answer \\\"{point}\\\" to the question \\\"{question}\\\":\\n\"\n",
        "        + \"\\n\".join([f\"{cluster_id}: {description}\" for cluster_id, description in clusters.items()])\n",
        "        + \"\\n\\nAnswer in one word with the ID.\"\n",
        "    )\n",
        "\n",
        "\n",
        "    best_cluster_id = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that can figure out how to categorize text properly.\"},\n",
        "        {\"role\": \"user\", \"content\":  prompt_cluster},\n",
        "    ],\n",
        "        temperature=0.5,\n",
        "        max_tokens=1500,\n",
        "        top_p=1.0,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    ).choices[0].message.content\n",
        "\n",
        "    return best_cluster_id\n",
        "\n",
        "# Example usage\n",
        "theme = \"research\"\n",
        "input_text = '''\n",
        "              One way I think we can achieve success is by Funding all projects,providing infrastructure,and hiring good people.\n",
        "             Another way , i think we can measure our success is to measure the output of the research conducted. Good people do critical research.\n",
        "             The problems I believe we face are Limited Funding: Insufficient financial resources can restrict the scope of research,\n",
        "              limit access to necessary materials or equipment, and constrain the ability to hire skilled personnel.\n",
        "            Access to Resources: Difficulty in accessing necessary research materials, data, or equipment can significantly hinder the research process.\n",
        "            Time Constraints: Researchers often face tight deadlines for completing their work, which can impact the depth and thoroughness of the research.\n",
        "            Ethical Considerations: Navigating ethical issues, especially in fields like medicine, psychology, and social sciences,\n",
        "            can be challenging and may limit the types of research that can be conducted.\n",
        "             '''\n",
        "clusters = {\n",
        "    \"A\": \"Improve management\",\n",
        "    \"B\": \"Foster tech Transfer\",\n",
        "    \"C\": \"Support publishing\",\n",
        "    \"D\": \"Personal Qualities\",\n",
        "    \"E\": \"Improve Infrastruture\",\n",
        "    \"F\": \"Smart Topic Selection\",\n",
        "    \"G\": \"Improve Research Funding\",\n",
        "    \"H\": \"Improve Human Capital\",\n",
        "    \"I\": \"Enhance Collaboration\",\n",
        "    \"G\":\"Promote Autonomy\"\n",
        "}\n",
        "\n",
        "analysis_result = analyze_and_categorize_responses(input_text, theme)\n",
        "# Assume `analysis_result` is a string with categorized responses.\n",
        "# You would parse this string to extract individual responses,\n",
        "# then loop through them to assign each to a cluster.\n",
        "\n",
        "# This is a simplified example. You'll need to implement parsing of `analysis_result`\n",
        "# based on its structure, then loop through each response to find its cluster.\n",
        "for response in analysis_result.split('\\n'):  # Simplified; actual parsing depends on analysis_result format.\n",
        "    best_cluster_id = find_cluster_for_response(theme, response, clusters)\n",
        "    print(f\"Response: {response}\\nBest Cluster: {best_cluster_id}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XUEXfestTXcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt(answer, category, theme, text):\n",
        "    # Mapping for argument types to corresponding phrases\n",
        "    argtype_phrases = {\"pro\": \"is\", \"con\": \"is NOT\"}\n",
        "\n",
        "    # Mapping category to corresponding phrase\n",
        "    category_phrases = {\n",
        "        \"metric\": f\"a good way to measure success in {theme}\",\n",
        "        \"barrier\": f\"an important barrier to success in {theme}\",\n",
        "        \"solution\": f\"a good way to achieve success in {theme}\"\n",
        "    }\n",
        "\n",
        "    prompts = []\n",
        "\n",
        "    for argtype in [\"pro\", \"con\"]:\n",
        "        # Constructing the prompt based on the current argtype\n",
        "        prompt = (f\"Give a bullet list of all the reasons, mentioned in the text below, \"\n",
        "                  f\"about why \\\"{answer}\\\" {argtype_phrases[argtype]} {category_phrases[category]}.\\n\"\n",
        "                  f\"\\nIf there are no reasons mentioned in the text, answer NONE.\"\n",
        "                  f\"\\n\\nGot it? OK. Give me a bullet list of the reasons mentioned in the following text:\\n\\n\\\"{text}\\\"\")\n",
        "        prompts.append(prompt)\n",
        "\n",
        "    return prompts\n",
        "\n",
        "# Example usage\n",
        "answer = \"Using AI in education\"\n",
        "category = \"solution\"\n",
        "theme = \"modern teaching methods\"\n",
        "text = \"The integration of AI into education can personalize learning, making it more effective.\"\n",
        "\n",
        "prompts = generate_prompt(answer, category, theme, text)\n",
        "\n",
        "# Print each prompt\n",
        "for prompt in prompts:\n",
        "    print(prompt)\n",
        "    print(\"\\n---\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCOFwR3T6nTw",
        "outputId": "868eb678-f931-46f7-f60c-8c5f93093527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Give a bullet list of all the reasons, mentioned in the text below, about why \"Using AI in education\" is a good way to achieve success in modern teaching methods.\n",
            "\n",
            "If there are no reasons mentioned in the text, answer NONE.\n",
            "\n",
            "Got it? OK. Give me a bullet list of the reasons mentioned in the following text:\n",
            "\n",
            "\"The integration of AI into education can personalize learning, making it more effective.\"\n",
            "\n",
            "---\n",
            "\n",
            "Give a bullet list of all the reasons, mentioned in the text below, about why \"Using AI in education\" is NOT a good way to achieve success in modern teaching methods.\n",
            "\n",
            "If there are no reasons mentioned in the text, answer NONE.\n",
            "\n",
            "Got it? OK. Give me a bullet list of the reasons mentioned in the following text:\n",
            "\n",
            "\"The integration of AI into education can personalize learning, making it more effective.\"\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt(answer, category, theme, text):\n",
        "    # Mapping for argument types to corresponding phrases\n",
        "    argtype_phrases = {\"pro\": \"is\", \"con\": \"is NOT\"}\n",
        "\n",
        "    # Mapping category to corresponding phrase\n",
        "    category_phrases = {\n",
        "        \"metric\": f\"a good way to measure success in {theme}\",\n",
        "        \"barrier\": f\"an important barrier to success in {theme}\",\n",
        "        \"solution\": f\"a good way to achieve success in {theme}\"\n",
        "    }\n",
        "\n",
        "    prompts = []\n",
        "\n",
        "    for argtype in [\"pro\", \"con\"]:\n",
        "        # Constructing the prompt based on the current argtype\n",
        "        prompt = (f\"Give a bullet list of all the reasons, mentioned in the text below, \"\n",
        "                  f\"about why \\\"{answer}\\\" {argtype_phrases[argtype]} {category_phrases[category]}.\\n\"\n",
        "                  f\"\\nIf there are no reasons mentioned in the text, answer NONE.\"\n",
        "                  f\"\\n\\nGot it? OK. Give me a bullet list of the reasons mentioned in the following text:\\n\\n\\\"{text}\\\"\")\n",
        "        prompts.append(prompt)\n",
        "\n",
        "    return prompts\n",
        "\n",
        "# Example usage\n",
        "answer = \"Using AI in education\"\n",
        "category = \"solution\"\n",
        "theme = \"modern teaching methods\"\n",
        "text = \"The integration of AI into education can personalize learning, making it more effective.\"\n",
        "\n",
        "prompts = generate_prompt(answer, category, theme, text)\n",
        "\n",
        "# Print each prompt\n",
        "for prompt in prompts:\n",
        "    print(prompt)\n",
        "    print(\"\\n---\\n\")\n"
      ],
      "metadata": {
        "id": "1vRZGTvQ7PmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_argument_prompts(answer, theme, text):\n",
        "    prompts = {\n",
        "        \"pro\": f\"List all the reasons that support the statement: '{answer}' is a good way to achieve success in {theme}.\",\n",
        "        \"con\": f\"List all the reasons against the statement: '{answer}' is not a good way to achieve success in {theme}.\"\n",
        "    }\n",
        "    results = {\n",
        "        \"pro\": [\"Reason 1 supporting the statement\", \"Reason 2 supporting the statement\"],\n",
        "        \"con\": [\"Reason 1 against the statement\", \"Reason 2 against the statement\"]\n",
        "    }\n",
        "    # For demonstration purposes, we're returning mock results.\n",
        "    # Replace with actual logic to extract reasons from text.\n",
        "    return results\n",
        "\n",
        "def classify_arguments(reasons, criteria):\n",
        "    # The criteria provided\n",
        "    criteria_prompts = {\n",
        "        \"actionable\": \"Is this answer actionable?\",\n",
        "        \"high_impact\": \"Is this answer of high impact?\"\n",
        "    }\n",
        "\n",
        "    classifications = []\n",
        "\n",
        "    # Classify each reason into one of the criteria\n",
        "    for reason in reasons:\n",
        "        for criterion_key, criterion_question in criteria_prompts.items():\n",
        "            prompt = (f\"Classify the reason '{reason}' into one of these categories:\\n\"\n",
        "                      f\"1. Actionable\\n\"\n",
        "                      f\"2. High Impact\\n\"\n",
        "                      f\"The reason implies that '{reason}' is an answer to the question '{criterion_question}'\\n\"\n",
        "                      f\"Answer with the number corresponding to the category.\")\n",
        "            classifications.append(prompt)\n",
        "\n",
        "    return classifications\n",
        "\n",
        "# Example usage\n",
        "answer = \"Using AI in education\"\n",
        "theme = \"modern teaching methods\"\n",
        "text = \"The integration of AI into education can personalize learning, making it more effective.\"\n",
        "criteria = [\"actionable\", \"high_impact\"]\n",
        "\n",
        "# Generate arguments from the text\n",
        "arguments = generate_argument_prompts(answer, theme, text)\n",
        "\n",
        "# Now classify each pro argument\n",
        "pro_classifications = classify_arguments(arguments['pro'], criteria)\n",
        "print(\"Pro Arguments Classification:\")\n",
        "for classification in pro_classifications:\n",
        "    print(classification)\n",
        "    print(\"\\n---\\n\")\n",
        "\n",
        "# Now classify each con argument\n",
        "con_classifications = classify_arguments(arguments['con'], criteria)\n",
        "print(\"Con Arguments Classification:\")\n",
        "for classification in con_classifications:\n",
        "    print(classification)\n",
        "    print(\"\\n---\\n\")\n"
      ],
      "metadata": {
        "id": "YevTJNYM7e3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2ND TRIAL"
      ],
      "metadata": {
        "id": "l4pgqK2-RISS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Set up your API key from an environment variable or directly inputting it\n",
        "openai.api_key = 'your-api-key'\n",
        "\n",
        "def extract_points_from_text(theme, text):\n",
        "    \"\"\"\n",
        "    Generates prompts based on a theme and sends them to the OpenAI API\n",
        "    to extract different answers from a piece of text.\n",
        "    \"\"\"\n",
        "    # List of categories you are interested in\n",
        "    categories = [\"SOLUTION\", \"METRIC\", \"BARRIER\"]\n",
        "\n",
        "    # Initialize a list to hold all the prompts\n",
        "    prompts = []\n",
        "\n",
        "    # Create prompts for each category\n",
        "    for category in categories:\n",
        "        prompt = (\n",
        "            f\"I want you to give me a bullet list of all the significantly different answers mentioned in the text below.\\n\"\n",
        "            \"Do NOT mention an answer more than once - be sure to remove duplicate points.\\n\"\n",
        "            f\"I am interested in the following types of answers:\\n\"\n",
        "            f\"- {category}: a way to {('achieve' if category == 'SOLUTION' else 'measure' if category == 'METRIC' else 'address a barrier to')} success in {theme}.\\n\"\n",
        "            \"For each point, give me the type of point (SOLUTION, METRIC, BARRIER) followed by, IN THE SAME LINE, all the text describing that point.\\n\"\n",
        "            \"Include enough context so each point makes sense on its own.\\n\"\n",
        "            \"If there are no points in the text, answer NONE.\\n\\n\"\n",
        "            f\"Text: \\\"{text}\\\"\"\n",
        "        )\n",
        "        prompts.append(prompt)\n",
        "\n",
        "    # Dictionary to store the responses for each category\n",
        "    points = {category: None for category in categories}\n",
        "\n",
        "    # Send each prompt to the OpenAI API and store the results\n",
        "    for prompt, category in zip(prompts, categories):\n",
        "        response = openai.Completion.create(\n",
        "            engine=\"davinci\",\n",
        "            prompt=prompt,\n",
        "            max_tokens=1024,\n",
        "            n=1,\n",
        "            stop=None,\n",
        "            temperature=0.3\n",
        "        )\n",
        "        points[category] = response.choices[0].text.strip()\n",
        "\n",
        "    return points\n",
        "\n",
        "# Example usage:\n",
        "theme = \"research\"\n",
        "text = \"Here is your text containing different people's responses on how to achieve success in research.\"\n",
        "extracted_points = extract_points_from_text(theme, text)\n",
        "\n",
        "# Print out the categorized points\n",
        "for category, points in extracted_points.items():\n",
        "    print(f\"{category} Points:\")\n",
        "    print(points)\n",
        "    print(\"\\n---\\n\")\n"
      ],
      "metadata": {
        "id": "OYTStSUiF37y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}